{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[Deep Learning Course Home Page](https://www.kaggle.com/learn/deep-learning)**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nYou've seen how to build a model from scratch to identify handwritten digits.  You'll now build a model to identify different types of clothing.  To make models that train quickly, we'll work with very small (low-resolution) images. \n\nAs an example, your model will take an images like this and identify it as a shoe:\n\n![Imgur](https://i.imgur.com/GyXOnSB.png)"},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation\nThis code is supplied, and you don't need to change it. Just run the cell below."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n\ndef prep_data(raw):\n    y = raw[:, 0]\n    out_y = keras.utils.to_categorical(y, num_classes)\n    \n    x = raw[:,1:]\n    num_images = raw.shape[0]\n    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n    out_x = out_x / 255\n    return out_x, out_y\n\nfashion_file = \"../input/fashionmnist/fashion-mnist_train.csv\"\nfashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\nx, y = prep_data(fashion_data)\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning.exercise_7 import *\nprint(\"Setup Complete\")","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow version 1.13.1\nSetup Complete\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 1) Start the model\nCreate a `Sequential` model called `fashion_model`. Don't add layers yet."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\n\n# Your Code Here\nfashion_model = Sequential()\nq_1.check()","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 91, \"questionId\": \"1_StartSequentialModel\", \"learnToolsVersion\": \"0.2.13\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"#q_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Add the first layer\n\nAdd the first `Conv2D` layer to `fashion_model`. It should have 12 filters, a kernel_size of 3 and the `relu` activation function. The first layer always requires that you specify the `input_shape`.  We have saved the number of rows and columns to the variables `img_rows` and `img_cols` respectively, so the input shape in this case is `(img_rows, img_cols, 1)`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here\nfashion_model.add(Conv2D(12, kernel_size=3, activation='relu', \n                         input_shape=(img_rows, img_cols, 1)))\nq_2.check()","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 91, \"questionId\": \"2_AddFirstLayer\", \"learnToolsVersion\": \"0.2.13\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# q_2.hint()\n#q_2.solution()","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Add the remaining layers\n\n1. Add 2 more convolutional (`Conv2D layers`) with 20 filters each, 'relu' activation, and a kernel size of 3. Follow that with a `Flatten` layer, and then a `Dense` layer with 100 neurons. \n2. Add your prediction layer to `fashion_model`.  This is a `Dense` layer.  We alrady have a variable called `num_classes`.  Use this variable when specifying the number of nodes in this layer. The activation should be `softmax` (or you will have problems later)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code here\n# 1\nfashion_model.add(Conv2D(20, kernel_size=3, activation='relu'))\nfashion_model.add(Conv2D(20, kernel_size=3, activation='relu'))\nfashion_model.add(Flatten())\nfashion_model.add(Dense(100))\n# 2\nfashion_model.add(Dense(10, activation='softmax'))\n\n#q_3.check()","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #q_3.solution()","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) Compile Your Model\nCompile fashion_model with the `compile` method.  Specify the following arguments:\n1. `loss = \"categorical_crossentropy\"`\n2. `optimizer = 'adam'`\n3. `metrics = ['accuracy']`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code to compile the model in this cell\nfashion_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nq_4.check()","execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 91, \"questionId\": \"4_CompileModel\", \"learnToolsVersion\": \"0.2.13\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# q_4.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5) Fit The Model\nRun the command `fashion_model.fit`. The arguments you will use are\n1. The data used to fit the model. First comes the data holding the images, and second is the data with the class labels to be predicted. Look at the first code cell (which was supplied to you) where we called `prep_data` to find the variable names for these.\n2. `batch_size = 100`\n3. `epochs = 4`\n4. `validation_split = 0.2`\n\nWhen you run this command, you can watch your model start improving.  You will see validation accuracies after each epoch."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code to fit the model here\nfashion_model.fit(x, y, batch_size=100, epochs=4, validation_split=0.2)\nq_5.check()","execution_count":33,"outputs":[{"output_type":"stream","text":"Train on 48000 samples, validate on 12000 samples\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/4\n48000/48000 [==============================] - 4s 90us/sample - loss: 0.4542 - acc: 0.8381 - val_loss: 0.3398 - val_acc: 0.8815\nEpoch 2/4\n48000/48000 [==============================] - 3s 62us/sample - loss: 0.2986 - acc: 0.8935 - val_loss: 0.3102 - val_acc: 0.8925\nEpoch 3/4\n48000/48000 [==============================] - 3s 61us/sample - loss: 0.2498 - acc: 0.9097 - val_loss: 0.2730 - val_acc: 0.9039\nEpoch 4/4\n48000/48000 [==============================] - 3s 60us/sample - loss: 0.2099 - acc: 0.9236 - val_loss: 0.2898 - val_acc: 0.8982\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 91, \"questionId\": \"5_FitFullDLModel\", \"learnToolsVersion\": \"0.2.13\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"#q_5.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6) Create A New Model\n\nCreate a new model called `second_fashion_model` in the cell below.  Make some changes so it is different than `fashion_model` that you've trained above. The change could be using a different number of layers, different number of convolutions in the layers, etc.\n\nDefine the model, compile it and fit it in the cell below.  See how it's validation score compares to that of the original model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Your code below\nsecond_fashion_model = Sequential()\n\nsecond_fashion_model.add(Conv2D(50, kernel_size=3, activation='relu', \n                                input_shape=(img_rows, img_cols, 1)))\nsecond_fashion_model.add(Conv2D(30, kernel_size=3, activation='relu'))\nsecond_fashion_model.add(Conv2D(20, kernel_size=3, activation='relu'))\nsecond_fashion_model.add(Conv2D(10, kernel_size=3, activation='relu'))\nsecond_fashion_model.add(Flatten())\nsecond_fashion_model.add(Dense(256))\nsecond_fashion_model.add(Dense(10, activation='softmax'))\n\nsecond_fashion_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nsecond_fashion_model.fit(x, y, epochs=8, validation_split=0.2)\n\nq_6.check()","execution_count":34,"outputs":[{"output_type":"stream","text":"Train on 48000 samples, validate on 12000 samples\nEpoch 1/8\n48000/48000 [==============================] - 9s 188us/sample - loss: 0.4371 - acc: 0.8404 - val_loss: 0.3498 - val_acc: 0.8763\nEpoch 2/8\n48000/48000 [==============================] - 9s 180us/sample - loss: 0.3049 - acc: 0.8892 - val_loss: 0.3134 - val_acc: 0.8894\nEpoch 3/8\n48000/48000 [==============================] - 9s 180us/sample - loss: 0.2621 - acc: 0.9048 - val_loss: 0.3006 - val_acc: 0.8981\nEpoch 4/8\n48000/48000 [==============================] - 9s 178us/sample - loss: 0.2318 - acc: 0.9156 - val_loss: 0.3092 - val_acc: 0.8937\nEpoch 5/8\n48000/48000 [==============================] - 9s 179us/sample - loss: 0.2135 - acc: 0.9223 - val_loss: 0.2736 - val_acc: 0.9074\nEpoch 6/8\n48000/48000 [==============================] - 9s 185us/sample - loss: 0.1933 - acc: 0.9292 - val_loss: 0.2960 - val_acc: 0.9013\nEpoch 7/8\n48000/48000 [==============================] - 9s 194us/sample - loss: 0.1778 - acc: 0.9346 - val_loss: 0.3195 - val_acc: 0.8938\nEpoch 8/8\n48000/48000 [==============================] - 9s 179us/sample - loss: 0.1630 - acc: 0.9387 - val_loss: 0.3110 - val_acc: 0.9024\nModel summary from second_fashion_model.summary()\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_18 (Conv2D)           (None, 26, 26, 50)        500       \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 24, 24, 30)        13530     \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 22, 22, 20)        5420      \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 20, 20, 10)        1810      \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 4000)              0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 256)               1024256   \n_________________________________________________________________\ndense_7 (Dense)              (None, 10)                2570      \n=================================================================\nTotal params: 1,048,086\nTrainable params: 1,048,086\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 91, \"questionId\": \"6_CreateNewDLModelFromScratch\", \"learnToolsVersion\": \"0.2.13\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"#q_6.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keep Going\nYou are ready to learn about **[strides and dropout](https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models)**, which become important as you start using bigger and more powerful models.\n"},{"metadata":{},"cell_type":"markdown","source":"---\n**[Deep Learning Course Home Page](https://www.kaggle.com/learn/deep-learning)**\n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}